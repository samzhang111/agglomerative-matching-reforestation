{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8986ba1-3ba3-448d-addb-e98377e44546",
   "metadata": {},
   "source": [
    "We achieve poor balance using the default algorithms in MatchIt, particularly because the treatment lands tend to be bigger than the control lands. But since we have way more control lands than treatment, and we're interested in the ATT, and since the distinctions between control lands aren't particularly important, we will _aggregate_ control lands together to form superlands to match to the treatment.\n",
    "\n",
    "This will be done in an approximate, greedy way, with the goal to create 1-1 matches between treatment lands and control superlands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25607e3-f150-42da-bbd2-c2fdc2a83c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pyprojroot.here import here\n",
    "from annoy import AnnoyIndex\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0446c9e4-a52d-40a3-a5d9-641274957354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1873211\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treat</th>\n",
       "      <th>area_final</th>\n",
       "      <th>forest1985</th>\n",
       "      <th>temp</th>\n",
       "      <th>precip</th>\n",
       "      <th>elevation</th>\n",
       "      <th>slope</th>\n",
       "      <th>pop_dens</th>\n",
       "      <th>dist_roads</th>\n",
       "      <th>dist_rivers</th>\n",
       "      <th>dist_cities</th>\n",
       "      <th>ephemeral_rest</th>\n",
       "      <th>persistent_rest</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.038080</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>1.122367</td>\n",
       "      <td>0.909230</td>\n",
       "      <td>0.647723</td>\n",
       "      <td>1.137466</td>\n",
       "      <td>0.161666</td>\n",
       "      <td>0.341784</td>\n",
       "      <td>0.224733</td>\n",
       "      <td>0.272358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.122367</td>\n",
       "      <td>0.910020</td>\n",
       "      <td>0.626401</td>\n",
       "      <td>0.564676</td>\n",
       "      <td>0.171645</td>\n",
       "      <td>0.246843</td>\n",
       "      <td>0.060279</td>\n",
       "      <td>0.272358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.023344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.124045</td>\n",
       "      <td>0.817861</td>\n",
       "      <td>0.569686</td>\n",
       "      <td>0.450653</td>\n",
       "      <td>0.707153</td>\n",
       "      <td>0.046968</td>\n",
       "      <td>0.065659</td>\n",
       "      <td>0.163415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.122367</td>\n",
       "      <td>0.819031</td>\n",
       "      <td>0.579695</td>\n",
       "      <td>0.889880</td>\n",
       "      <td>0.707153</td>\n",
       "      <td>0.082221</td>\n",
       "      <td>0.096388</td>\n",
       "      <td>0.163415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>0.017129</td>\n",
       "      <td>1.137466</td>\n",
       "      <td>0.840758</td>\n",
       "      <td>0.546205</td>\n",
       "      <td>1.202641</td>\n",
       "      <td>0.254516</td>\n",
       "      <td>0.076963</td>\n",
       "      <td>0.267657</td>\n",
       "      <td>0.062253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.614985</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    treat  area_final  forest1985      temp    precip  elevation     slope  \\\n",
       "id                                                                           \n",
       "1       0    0.038080    0.001081  1.122367  0.909230   0.647723  1.137466   \n",
       "2       0    0.011091    0.000000  1.122367  0.910020   0.626401  0.564676   \n",
       "3       0    0.023344    0.000000  1.124045  0.817861   0.569686  0.450653   \n",
       "4       0    0.003063    0.000000  1.122367  0.819031   0.579695  0.889880   \n",
       "5       0    0.017007    0.017129  1.137466  0.840758   0.546205  1.202641   \n",
       "\n",
       "    pop_dens  dist_roads  dist_rivers  dist_cities  ephemeral_rest  \\\n",
       "id                                                                   \n",
       "1   0.161666    0.341784     0.224733     0.272358             0.0   \n",
       "2   0.171645    0.246843     0.060279     0.272358             0.0   \n",
       "3   0.707153    0.046968     0.065659     0.163415             0.0   \n",
       "4   0.707153    0.082221     0.096388     0.163415             0.0   \n",
       "5   0.254516    0.076963     0.267657     0.062253             0.0   \n",
       "\n",
       "    persistent_rest  id  \n",
       "id                       \n",
       "1          0.000000   1  \n",
       "2          0.000000   2  \n",
       "3          0.000000   3  \n",
       "4          0.000000   4  \n",
       "5          2.614985   5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(here(\"import/output/com_priv.csv\"))\n",
    "df = df.drop(['Unnamed: 0', 'land_type2'], axis=1)\n",
    "df = df.set_index(df['id'])\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "6e104ba2-54a7-4170-9a9d-765602a992ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_col='area_final'\n",
    "cols_to_sum=['area_final', 'forest1985', 'persistent_rest', 'ephemeral_rest']\n",
    "outcomes=['persistent_rest', 'ephemeral_rest']\n",
    "cols_to_drop=['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "918607e0-040d-4a4b-bed0-7fbc3daea029",
   "metadata": {},
   "outputs": [],
   "source": [
    "treat = df[df.treat == 1].drop(['treat'] + cols_to_sum + cols_to_drop, axis=1)\n",
    "treat_with_area = df[df.treat == 1].drop(['treat'], axis=1)\n",
    "\n",
    "control = df[df.treat == 0].drop(['treat'] + cols_to_sum + cols_to_drop, axis=1)\n",
    "control_with_area = df[df.treat == 0].drop(['treat'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "379c477f-0cfd-4e3e-96ee-0bd2c10c6e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................................................................................................................"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_index = AnnoyIndex(control.shape[1], 'euclidean') # Remove the index and the \"treatment\" columns\n",
    "for i, (ix, row) in enumerate(control.iterrows()):\n",
    "    if i % 10000 == 0:\n",
    "        print('.', end='')\n",
    "    control_index.add_item(ix, row.values)\n",
    "\n",
    "control_index.build(10) # 10 trees\n",
    "control_index.save(str(here(\"matching/cache/com_priv_control.nn\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6e38b885-aad2-4f90-bcbc-9557cbf633f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_subset_with_averaging(target, vectors):\n",
    "    \"\"\"\n",
    "    Find a subset of vectors that adheres to custom summation and averaging rules\n",
    "    to get as close as possible to the target.\n",
    "    \n",
    "    Args:\n",
    "    - target (numpy array): N-dimensional target vector\n",
    "    - vectors (numpy array): Array of N-dimensional vectors\n",
    "    \n",
    "    Returns:\n",
    "    - list: Indices of the chosen vectors\n",
    "    \"\"\"\n",
    "    current_sum = np.array([0.0] * target.shape[0])\n",
    "    chosen_indices = []\n",
    "    \n",
    "    # Create an array of indices corresponding to the vectors\n",
    "    indices = np.arange(vectors.shape[0])\n",
    "    \n",
    "    while len(vectors) > 0 and not np.allclose(current_sum[:2], target[:2]):\n",
    "        # Calculate potential sums for the first two components\n",
    "        potential_sums = vectors.copy()\n",
    "        potential_sums[:, :2] += current_sum[:2]\n",
    "        \n",
    "        # For the 3rd to Nth components, compute the potential weighted averages\n",
    "        weight_totals = vectors[:, 0] + current_sum[0]\n",
    "        for i in range(2, target.shape[0]):\n",
    "            potential_sums[:, i] = (vectors[:, 0] * vectors[:, i] + current_sum[0] * current_sum[i]) / weight_totals\n",
    "        \n",
    "        # Calculate distances to target for each potential sum\n",
    "        distances = np.linalg.norm(potential_sums - target, axis=1)\n",
    "        best_index = np.argmin(distances)\n",
    "\n",
    "        # If adding the best vector makes the solution worse, bail out\n",
    "        if distances[best_index] > np.linalg.norm(current_sum - target):\n",
    "            break\n",
    "\n",
    "        # Update the weighted averages for the 3rd to Nth components\n",
    "        current_sum[2:] = (current_sum[0] * current_sum[2:] + vectors[best_index, 0] * vectors[best_index, 2:]) / (current_sum[0] + vectors[best_index, 0])\n",
    "        \n",
    "        # Update current sum for the first two components\n",
    "        current_sum[:2] += vectors[best_index, :2]\n",
    "        chosen_indices.append(indices[best_index])\n",
    "        \n",
    "        # Remove the selected vector and its index from consideration\n",
    "        vectors = np.delete(vectors, best_index, axis=0)\n",
    "        indices = np.delete(indices, best_index, axis=0)\n",
    "\n",
    "    return chosen_indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "24c2b07d-7d23-4db9-8148-c7bb993c2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacky global variable: this needs to be reset before runs\n",
    "exclude_ids = set()\n",
    "\n",
    "def make_superland_for_treatment_land(ta, area_col='area_final', cols_to_sum=['area_final', 'forest1985', 'persistent_rest', 'ephemeral_rest'], outcomes=['persistent_rest', 'ephemeral_rest'], cols_to_drop=['id']):\n",
    "    ta_use = ta.drop(cols_to_drop + outcomes)\n",
    "    control_use = control_with_area.drop(cols_to_drop + outcomes, axis=1)\n",
    "    t = ta_use.drop(cols_to_sum, errors='ignore')\n",
    "    nearest_results = set(control_index.get_nns_by_vector(t.values, 1000)) - exclude_ids\n",
    "    nearest = np.array(list(nearest_results))\n",
    "    candidates = control_use.loc[nearest].to_numpy()\n",
    "    component_lands = closest_subset_with_averaging(ta_use.values, candidates)\n",
    "\n",
    "    df_super = control_with_area.loc[nearest[component_lands]]\n",
    "\n",
    "    # Weighted average of those columns\n",
    "    df_super_combined = df_super.drop(cols_to_sum + outcomes + cols_to_drop, axis=1).multiply(df_super[area_col], axis='index').sum(axis=0) / df_super[area_col].sum()\n",
    "    \n",
    "    # Sum of the remaining columns\n",
    "    for col in cols_to_sum:\n",
    "        df_super_combined[col] = df_super[col].sum()\n",
    "\n",
    "    # Treatment ID\n",
    "    df_super_combined['treatment_id'] = ta.name\n",
    "\n",
    "    # Control IDs\n",
    "    df_super_combined['control_ids'] = df_super.agg({'id': list})['id']\n",
    "    exclude_ids.update(df_super_combined['control_ids'])\n",
    "    \n",
    "    return df_super_combined\n",
    "\n",
    "make_superland_for_treatment_land(treat_with_area.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "b626a6af-c82f-40ed-9a8a-36b42bb9fe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................."
     ]
    }
   ],
   "source": [
    "exclude_ids = set()\n",
    "superlands = []\n",
    "\n",
    "for i, ta in treat_with_area.iterrows():\n",
    "    if i % 100 == 0:\n",
    "        print('.', end='')\n",
    "    result = make_superland_for_treatment_land(ta)\n",
    "    if result is not None:\n",
    "        superlands.append((ta, result, sum((ta - result)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "c1affd49-ad92-4fbe-b24b-e9e9c11af595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1661"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_superlands = pd.DataFrame([x[1] for x in superlands]).dropna()\n",
    "len(df_superlands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "674b5658-3073-4edc-89de-acd7340e356a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "control_ids\n",
       "3      463\n",
       "2      395\n",
       "4      276\n",
       "1      256\n",
       "5      115\n",
       "6       58\n",
       "7       22\n",
       "9       10\n",
       "8       10\n",
       "11       7\n",
       "19       3\n",
       "13       3\n",
       "10       3\n",
       "12       3\n",
       "26       2\n",
       "16       2\n",
       "44       1\n",
       "17       1\n",
       "32       1\n",
       "461      1\n",
       "56       1\n",
       "167      1\n",
       "21       1\n",
       "85       1\n",
       "18       1\n",
       "377      1\n",
       "216      1\n",
       "539      1\n",
       "869      1\n",
       "65       1\n",
       "14       1\n",
       "46       1\n",
       "20       1\n",
       "50       1\n",
       "70       1\n",
       "124      1\n",
       "630      1\n",
       "66       1\n",
       "943      1\n",
       "438      1\n",
       "29       1\n",
       "60       1\n",
       "253      1\n",
       "245      1\n",
       "169      1\n",
       "171      1\n",
       "569      1\n",
       "34       1\n",
       "23       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_superlands.control_ids.str.len().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "d8c8051e-28c6-4c40-8aec-36c8681815e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12030 12030\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "cids = list(chain(*df_superlands['control_ids'].values))\n",
    "\n",
    "# For confirming that each control unit are never reused in constructing superlands\n",
    "\n",
    "print(len(set(cids)), len(cids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "fe6945da-9933-4623-a1b1-39fb16661af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1661, 14)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_superlands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "571dd3ce-a68f-4c0c-9361-76eed44d09e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_superlands.to_csv(here(\"matching/output/com_priv_superlands.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
